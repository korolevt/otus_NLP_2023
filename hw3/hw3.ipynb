{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3  –ß—Ç–æ –≤ –≤–µ–∫—Ç–æ—Ä–µ —Ç–≤–æ–µ–º?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests      # –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤\n",
    "import numpy as np   # –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –º–∞—Ç—Ä–∏—Ü, –≤–µ–∫—Ç–æ—Ä–æ–≤ –∏ –ª–∏–Ω–∞–ª–∞\n",
    "import pandas as pd  # –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è —Ç–∞–±–ª–∏—á–µ–∫\n",
    "import time          # –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –î–ó-1 –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö (https://github.com/korolevt/otus_NLP_2023/blob/main/hw1/hw1.ipynb)\n",
    "–ö–æ—Ç–æ—Ä–∞—è —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ –∫ —Ñ–∏–ª—å–º–∞–º, —Å –æ—Ü–µ–Ω–∫–∞–º–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"–ü–µ—Ä–µ—Å—Ç–∞–Ω—å –≤–æ–ª–Ω–æ–≤–∞—Ç—å—Å—è –æ —Ç–æ–º, —á—Ç–æ –Ω–µ –º–æ–∂–µ—à—å –∫–æ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–î–≤–æ–µ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ –∫–æ—Å–º–∏—á–µ—Å–∫–æ–≥–æ –∫–æ—Ä–∞–±–ª—è, –ø—Ä–æ—Å—ã–ø–∞—é...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–î–∞–≤–Ω–æ –Ω–µ –≤–∏–¥–µ–ª–∞ —Ç–∞–∫–∏—Ö –±—Ä–µ–¥–æ–≤—ã—Ö —Ñ–∏–ª—å–º–æ–≤. \"–ü–∞—Å—Å–∞...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ß–µ–ª–æ–≤–µ–∫—É –Ω—É–∂–µ–Ω —á–µ–ª–æ–≤–µ–∫. –ï—Å–ª–∏ –Ω–µ–ª—å–∑—è, –Ω–æ –æ—á–µ–Ω—å ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–ù–µ–ø–ª–æ—Ö–∞—è –≤–∞—Ä–∏–∞—Ü–∏—è –Ω–∞ —Ç–µ–º—É –∫–æ—Å–º–æ—Å–∞ –∏ –æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–∞</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6742</th>\n",
       "      <td>–§–∏–ª—å–º, –∫–æ—Ç–æ—Ä—ã–π —Å—Ç–æ–∏—Ç –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6743</th>\n",
       "      <td>–ó–∞–≤–æ—Ä–∞–∂–∏–≤–∞—é—â–∏–π - breathtaking!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6744</th>\n",
       "      <td>–ú–∞–ª–µ—Ñ–∏—Å–µ–Ω—Ç–∞-2 - —Å–∏–∫–≤–µ–ª —É–¥–∞–ª—Å—è, –∏–ª–∏ –º–æ–∏ –≤–ø–µ—á–∞—Ç–ª...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6745</th>\n",
       "      <td>–í–∞—É!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6746</th>\n",
       "      <td>–ö—Ä–∞—Å–∏–≤–∞—è —Å–∫–∞–∑–∫–∞ —Å –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–º —Å—é–∂–µ—Ç–æ–º. –ü–æ–Ω–∏–º...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6747 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment  Rating\n",
       "0     \"–ü–µ—Ä–µ—Å—Ç–∞–Ω—å –≤–æ–ª–Ω–æ–≤–∞—Ç—å—Å—è –æ —Ç–æ–º, —á—Ç–æ –Ω–µ –º–æ–∂–µ—à—å –∫–æ...       5\n",
       "1     –î–≤–æ–µ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ –∫–æ—Å–º–∏—á–µ—Å–∫–æ–≥–æ –∫–æ—Ä–∞–±–ª—è, –ø—Ä–æ—Å—ã–ø–∞—é...       4\n",
       "2     –î–∞–≤–Ω–æ –Ω–µ –≤–∏–¥–µ–ª–∞ —Ç–∞–∫–∏—Ö –±—Ä–µ–¥–æ–≤—ã—Ö —Ñ–∏–ª—å–º–æ–≤. \"–ü–∞—Å—Å–∞...       1\n",
       "3     –ß–µ–ª–æ–≤–µ–∫—É –Ω—É–∂–µ–Ω —á–µ–ª–æ–≤–µ–∫. –ï—Å–ª–∏ –Ω–µ–ª—å–∑—è, –Ω–æ –æ—á–µ–Ω—å ...       5\n",
       "4       –ù–µ–ø–ª–æ—Ö–∞—è –≤–∞—Ä–∏–∞—Ü–∏—è –Ω–∞ —Ç–µ–º—É –∫–æ—Å–º–æ—Å–∞ –∏ –æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–∞       4\n",
       "...                                                 ...     ...\n",
       "6742                  –§–∏–ª—å–º, –∫–æ—Ç–æ—Ä—ã–π —Å—Ç–æ–∏—Ç –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å!        5\n",
       "6743                     –ó–∞–≤–æ—Ä–∞–∂–∏–≤–∞—é—â–∏–π - breathtaking!       5\n",
       "6744  –ú–∞–ª–µ—Ñ–∏—Å–µ–Ω—Ç–∞-2 - —Å–∏–∫–≤–µ–ª —É–¥–∞–ª—Å—è, –∏–ª–∏ –º–æ–∏ –≤–ø–µ—á–∞—Ç–ª...       4\n",
       "6745                                               –í–∞—É!       5\n",
       "6746  –ö—Ä–∞—Å–∏–≤–∞—è —Å–∫–∞–∑–∫–∞ —Å –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–º —Å—é–∂–µ—Ç–æ–º. –ü–æ–Ω–∏–º...       4\n",
       "\n",
       "[6747 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"data.pkl\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º dataframe –≤ json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_json(orient='records')\n",
    "data = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Comment': '\"–ü–µ—Ä–µ—Å—Ç–∞–Ω—å –≤–æ–ª–Ω–æ–≤–∞—Ç—å—Å—è –æ —Ç–æ–º, —á—Ç–æ –Ω–µ –º–æ–∂–µ—à—å –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å, –ø—Ä–æ—Å—Ç–æ –∂–∏–≤–∏\" - –ø–æ–∂–∞–ª—É–π, —ç—Ç–æ —Å–∞–º—ã–π –ª—É—á—à–∏–π –∂–∏–∑–Ω–µ–Ω–Ω—ã–π —Å–æ–≤–µ—Ç|–†–æ–±–∏–Ω–∑–æ–Ω–∞–¥–∞ –≤ –∫–æ—Å–º–æ—Å–µ‚ú®üåô|–û–¥–∏–Ω –∏–∑ –º–æ–∏—Ö –ª—é–±–∏–º—ã—Ö —Ñ–∏–ª—å–º–æ–≤. –ö–æ–≥–¥–∞ –º–Ω–µ –≥—Ä—É—Å—Ç–Ω–æ, —è –≤–∫–ª—é—á–∞—é \"–ü–∞—Å—Å–∞–∂–∏—Ä—ã\".',\n",
       " 'Rating': 5}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(5, 4469), (4, 1066), (3, 609), (2, 329), (1, 274)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(len(data))\n",
    "Counter([x['Rating'] for x in data]).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–£–¥–∞–ª—è–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞, –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tima-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk   # Natural Language Toolkit\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('russian')\n",
    "\n",
    "word_tokenizer = nltk.WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regex = re.compile(r'[–ê-–Ø–∞-—èA-z—ë–Å]+')\n",
    "\n",
    "import string\n",
    "spec_chars = string.punctuation + '\\d\\n\\xa0¬´¬ª\\t‚Äî‚Ä¶' \n",
    "regex2 = re.compile('[' + spec_chars + ']')\n",
    "\n",
    "#–£–±–∏—Ä–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –∏ –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω–æ–µ\n",
    "def words_only(text):\n",
    "    try:\n",
    "        return \" \".join(regex.findall(text)).lower()\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "#–£–±–∏—Ä–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é, –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º —Å–º–∞–π–ª–∏–∫–∏\n",
    "def words_only2(text):\n",
    "    try:\n",
    "        return re.sub(regex2, '', text.lower())\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def process_data(data):\n",
    "    texts = []\n",
    "    targets = []\n",
    "\n",
    "    # –ø–æ–æ—á–µ—Ä–µ–¥–Ω–æ –ø—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –Ω–æ–≤–æ—Å—Ç—è–º –≤ —Å–ø–∏—Å–∫–µ\n",
    "    for item in tqdm(data):\n",
    "\n",
    "        text_lower = words_only2(item['Comment']) # –æ—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞\n",
    "        tokens     = word_tokenizer.tokenize(text_lower) #—Ä–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª–æ–≤–∞\n",
    "\n",
    "        # —É–¥–∞–ª—è–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –∏ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞\n",
    "        tokens = [word for word in tokens if (word not in stop_words and not word.isnumeric())]\n",
    "\n",
    "        texts.append(tokens) # –¥–æ–±–∞–≤–ª—è–µ–º –≤ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\\\d\\n\\xa0¬´¬ª\\t‚Äî‚Ä¶'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6747/6747 [00:00<00:00, 36452.57it/s]\n"
     ]
    }
   ],
   "source": [
    "y = [item['Rating'] for item in data]\n",
    "texts = process_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating:  5\n",
      "Comment:  ['–ø–µ—Ä–µ—Å—Ç–∞–Ω—å', '–≤–æ–ª–Ω–æ–≤–∞—Ç—å—Å—è', '–º–æ–∂–µ—à—å', '–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å', '–ø—Ä–æ—Å—Ç–æ', '–∂–∏–≤–∏', '–ø–æ–∂–∞–ª—É–π', '—ç—Ç–æ', '—Å–∞–º—ã–π', '–ª—É—á—à–∏–π', '–∂–∏–∑–Ω–µ–Ω–Ω—ã–π', '—Å–æ–≤–µ—Ç—Ä–æ–±–∏–Ω–∑–æ–Ω–∞–¥–∞', '–∫–æ—Å–º–æ—Å–µ', '‚ú®üåô', '–º–æ–∏—Ö', '–ª—é–±–∏–º—ã—Ö', '—Ñ–∏–ª—å–º–æ–≤', '–≥—Ä—É—Å—Ç–Ω–æ', '–≤–∫–ª—é—á–∞—é', '–ø–∞—Å—Å–∞–∂–∏—Ä—ã']\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "i = 0\n",
    "print(\"Rating: \", y[i])\n",
    "print(\"Comment: \", texts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pymorphy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∑–∞–≥—Ä—É–∂–∞–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫—É –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏\n",
    "import pymorphy3 # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä\n",
    "\n",
    "# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä :)\n",
    "morph = pymorphy3.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: –ø–µ—Ä–µ—Å—Ç–∞–Ω—å\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: –ø–µ—Ä–µ—Å—Ç–∞—Ç—å\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: –≤–æ–ª–Ω–æ–≤–∞—Ç—å—Å—è\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: –≤–æ–ª–Ω–æ–≤–∞—Ç—å—Å—è\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: –º–æ–∂–µ—à—å\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: –º–æ—á—å\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: –ø—Ä–æ—Å—Ç–æ\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: –ø—Ä–æ—Å—Ç–æ\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: –∂–∏–≤–∏\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: –∂–∏–≤–∏—Ç—å\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: –ø–æ–∂–∞–ª—É–π\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: –ø–æ–∂–∞–ª—É–π\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: —ç—Ç–æ\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: —ç—Ç–æ\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: —Å–∞–º—ã–π\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: —Å–∞–º—ã–π\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: –ª—É—á—à–∏–π\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: —Ö–æ—Ä–æ—à–∏–π\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: –∂–∏–∑–Ω–µ–Ω–Ω—ã–π\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: –∂–∏–∑–Ω–µ–Ω–Ω—ã–π\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: —Å–æ–≤–µ—Ç—Ä–æ–±–∏–Ω–∑–æ–Ω–∞–¥–∞\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: —Å–æ–≤–µ—Ç—Ä–æ–±–∏–Ω–∑–æ–Ω–∞–¥–∞\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: –∫–æ—Å–º–æ—Å–µ\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: –∫–æ—Å–º–æ—Å\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: ‚ú®üåô\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: ‚ú®üåô\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: –º–æ–∏—Ö\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: –º–æ–π\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: –ª—é–±–∏–º—ã—Ö\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: –ª—é–±–∏–º—ã–π\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: —Ñ–∏–ª—å–º–æ–≤\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: —Ñ–∏–ª—å–º\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: –≥—Ä—É—Å—Ç–Ω–æ\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: –≥—Ä—É—Å—Ç–Ω–æ\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: –≤–∫–ª—é—á–∞—é\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: –≤–∫–ª—é—á–∞—Ç—å\n",
      "–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: –ø–∞—Å—Å–∞–∂–∏—Ä—ã\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: –ø–∞—Å—Å–∞–∂–∏—Ä\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for aword in texts[i]:\n",
    "    aword_norm = morph.parse(aword)[0].normal_form\n",
    "    print(\"–ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ: %s\\t–õ–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ: %s\" % (aword, aword_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ø—Ä–∏–º–µ–Ω—è–µ–º –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é –∫–æ –≤—Å–µ–º —Ç–µ–∫—Å—Ç–∞–º\n",
    "texts_normal = texts.copy()\n",
    "for i in range(len(texts)):           # tqdm_notebook —Å–æ–∑–¥–∞–µ—Ç —à–∫–∞–ª—É –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ :)\n",
    "    text_lemmatized = [morph.parse(x)[0].normal_form for x in texts[i]] # –ø—Ä–∏–º–µ–Ω—è–µ–º –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–µ\n",
    "    texts_normal[i] = ' '.join(text_lemmatized)                # –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating:  5\n",
      "Comment:  –ø–µ—Ä–µ—Å—Ç–∞—Ç—å –≤–æ–ª–Ω–æ–≤–∞—Ç—å—Å—è –º–æ—á—å –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç–æ –∂–∏–≤–∏—Ç—å –ø–æ–∂–∞–ª—É–π —ç—Ç–æ —Å–∞–º—ã–π —Ö–æ—Ä–æ—à–∏–π –∂–∏–∑–Ω–µ–Ω–Ω—ã–π —Å–æ–≤–µ—Ç—Ä–æ–±–∏–Ω–∑–æ–Ω–∞–¥–∞ –∫–æ—Å–º–æ—Å ‚ú®üåô –º–æ–π –ª—é–±–∏–º—ã–π —Ñ–∏–ª—å–º –≥—Ä—É—Å—Ç–Ω–æ –≤–∫–ª—é—á–∞—Ç—å –ø–∞—Å—Å–∞–∂–∏—Ä\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "i = 0\n",
    "print(\"Rating: \", y[i])\n",
    "print(\"Comment: \", texts_normal[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é</b>\n",
    "\n",
    "```\n",
    "–ì–¥–µ –æ—Ü–µ–Ω–∫–∞ 1-3 - —ç—Ç–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –æ—Ç–∑—ã–≤—ã\n",
    "–ì–¥–µ –æ—Ü–µ–Ω–∫–∞ 4-5 - —ç—Ç–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–∑—ã–≤—ã\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –ª–µ–π–±–ª–æ–≤\n",
    "def num2boolean(y):\n",
    "    if y == 1 or y == 2 or y == 3:\n",
    "        return 0\n",
    "    if y == 4 or y == 5:\n",
    "        return 1\n",
    "\n",
    "y = [num2boolean(yy) for yy in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 5535, 0: 1212})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–∑–±–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, test_texts, train_y, test_y = train_test_split(texts_normal, y, test_size=0.20, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(min_df=2, ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(min_df=2, ngram_range=(1, 2))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(min_df=2, ngram_range=(1, 2))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#–≤—ã—á–∏—Å–ª—è–µ–º tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Fit TF-IDF on train texts\n",
    "#vectorizer = TfidfVectorizer(max_features = 1000, norm = None) # –≤–æ–∑–º–µ–º —Ç–æ–ø 1000 —Å–ª–æ–≤\n",
    "vectorizer = TfidfVectorizer( ngram_range=(1,2), min_df=2)\n",
    "vectorizer.fit(train_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–±—É—á–∞–µ–º TF-IDF –Ω–∞ train, –∞ –∑–∞—Ç–µ–º –ø—Ä–∏–º–µ–Ω—è–µ–º –∫ train –∏ test\n",
    "train_X = vectorizer.fit_transform(train_texts)\n",
    "test_X  = vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['—Ñ–∏–ª—å–º', '—Ö–æ—Ä–æ—à–∏–π', '—Å–º–æ—Ç—Ä–µ—Ç—å', '–æ—á–µ–Ω—å', '—Ö–æ—Ä–æ—à–∏–π —Ñ–∏–ª—å–º', '—ç—Ç–æ',\n",
       "       '—à–µ–¥–µ–≤—Ä', '–∫–æ—Ç–æ—Ä—ã–π', '–ø—Ä–æ—Å–º–æ—Ç—Ä', '—Å–ª–µ–∑–∞'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤\n",
    "tfidf_feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "tfidf_sorting = np.argsort(np.asarray(train_X.sum(axis=0)).ravel())[::-1]\n",
    "n = 10\n",
    "tfidf_feature_names[tfidf_sorting[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "—Ñ–∏–ª—å–º                                              Score: 298.6678111467953\n",
      "—Ö–æ—Ä–æ—à–∏–π                                            Score: 138.18984580969186\n",
      "—Å–º–æ—Ç—Ä–µ—Ç—å                                           Score: 91.329489526741\n",
      "–æ—á–µ–Ω—å                                              Score: 81.99564750674608\n",
      "—Ö–æ—Ä–æ—à–∏–π —Ñ–∏–ª—å–º                                      Score: 75.90427594535214\n",
      "—ç—Ç–æ                                                Score: 75.76494187710762\n",
      "—à–µ–¥–µ–≤—Ä                                             Score: 65.78961846216994\n",
      "–∫–æ—Ç–æ—Ä—ã–π                                            Score: 62.77254715627877\n",
      "–ø—Ä–æ—Å–º–æ—Ç—Ä                                           Score: 56.62598978848509\n",
      "—Å–ª–µ–∑–∞                                              Score: 55.506075571525194\n",
      "–ø–æ–Ω—Ä–∞–≤–∏—Ç—å—Å—è                                        Score: 51.889224451897704\n",
      "–≤—Ä–µ–º—è                                              Score: 51.664639281614214\n",
      "–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å                                         Score: 51.479607007589216\n",
      "–∂–∏–∑–Ω—å                                              Score: 49.934426153580425\n",
      "–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π                                      Score: 48.442131933213844\n",
      "–æ—Ç–ª–∏—á–Ω—ã–π                                           Score: 45.13483968267283\n",
      "–ª—é–±–æ–≤—å                                             Score: 43.06336795075624\n",
      "—Ñ–∏–ª—å–º –∫–æ—Ç–æ—Ä—ã–π                                      Score: 40.474037236183044\n",
      "–∫–∏–Ω–æ                                               Score: 39.89242075768051\n",
      "–æ—Ç–ª–∏—á–Ω–æ                                            Score: 39.88649198959723\n"
     ]
    }
   ],
   "source": [
    "def display_scores(vectorizer, tfidf_result):\n",
    "    # http://stackoverflow.com/questions/16078015/\n",
    "    scores = zip(vectorizer.get_feature_names_out(),\n",
    "                 np.asarray(tfidf_result.sum(axis=0)).ravel())\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    for item in sorted_scores[:20]:\n",
    "        print (\"{0:50} Score: {1}\".format(item[0], item[1]))\n",
    "display_scores(vectorizer, train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–¥–µ—Å—å —ç—Ç–æ –Ω–µ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è, —Ç–∞–∫ –∫–∞–∫ —É –Ω–∞—Å —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ª–∞–π–±–µ–ª –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ - –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π/–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–∑—ã–≤\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#le = LabelEncoder()\n",
    "#le.fit(train_y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  RandomForest (–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START max_depth=10, n_estimators=500..............................\n",
      "[CV 1/5; 1/9] END max_depth=10, n_estimators=500;, score=0.901 total time=   3.5s\n",
      "[CV 2/5; 1/9] START max_depth=10, n_estimators=500..............................\n",
      "[CV 2/5; 1/9] END max_depth=10, n_estimators=500;, score=0.901 total time=   3.6s\n",
      "[CV 3/5; 1/9] START max_depth=10, n_estimators=500..............................\n",
      "[CV 3/5; 1/9] END max_depth=10, n_estimators=500;, score=0.902 total time=   3.4s\n",
      "[CV 4/5; 1/9] START max_depth=10, n_estimators=500..............................\n",
      "[CV 4/5; 1/9] END max_depth=10, n_estimators=500;, score=0.901 total time=   4.0s\n",
      "[CV 5/5; 1/9] START max_depth=10, n_estimators=500..............................\n",
      "[CV 5/5; 1/9] END max_depth=10, n_estimators=500;, score=0.901 total time=   3.7s\n",
      "[CV 1/5; 2/9] START max_depth=10, n_estimators=1000.............................\n",
      "[CV 1/5; 2/9] END max_depth=10, n_estimators=1000;, score=0.901 total time=   7.5s\n",
      "[CV 2/5; 2/9] START max_depth=10, n_estimators=1000.............................\n",
      "[CV 2/5; 2/9] END max_depth=10, n_estimators=1000;, score=0.901 total time=   8.0s\n",
      "[CV 3/5; 2/9] START max_depth=10, n_estimators=1000.............................\n",
      "[CV 3/5; 2/9] END max_depth=10, n_estimators=1000;, score=0.902 total time=   7.5s\n",
      "[CV 4/5; 2/9] START max_depth=10, n_estimators=1000.............................\n",
      "[CV 4/5; 2/9] END max_depth=10, n_estimators=1000;, score=0.901 total time=   8.6s\n",
      "[CV 5/5; 2/9] START max_depth=10, n_estimators=1000.............................\n",
      "[CV 5/5; 2/9] END max_depth=10, n_estimators=1000;, score=0.901 total time=   8.0s\n",
      "[CV 1/5; 3/9] START max_depth=10, n_estimators=1500.............................\n",
      "[CV 1/5; 3/9] END max_depth=10, n_estimators=1500;, score=0.901 total time=  12.9s\n",
      "[CV 2/5; 3/9] START max_depth=10, n_estimators=1500.............................\n",
      "[CV 2/5; 3/9] END max_depth=10, n_estimators=1500;, score=0.901 total time=  13.0s\n",
      "[CV 3/5; 3/9] START max_depth=10, n_estimators=1500.............................\n",
      "[CV 3/5; 3/9] END max_depth=10, n_estimators=1500;, score=0.902 total time=  11.9s\n",
      "[CV 4/5; 3/9] START max_depth=10, n_estimators=1500.............................\n",
      "[CV 4/5; 3/9] END max_depth=10, n_estimators=1500;, score=0.901 total time=  12.6s\n",
      "[CV 5/5; 3/9] START max_depth=10, n_estimators=1500.............................\n",
      "[CV 5/5; 3/9] END max_depth=10, n_estimators=1500;, score=0.901 total time=  12.0s\n",
      "[CV 1/5; 4/9] START max_depth=25, n_estimators=500..............................\n",
      "[CV 1/5; 4/9] END max_depth=25, n_estimators=500;, score=0.901 total time=   9.8s\n",
      "[CV 2/5; 4/9] START max_depth=25, n_estimators=500..............................\n",
      "[CV 2/5; 4/9] END max_depth=25, n_estimators=500;, score=0.902 total time=   9.6s\n",
      "[CV 3/5; 4/9] START max_depth=25, n_estimators=500..............................\n",
      "[CV 3/5; 4/9] END max_depth=25, n_estimators=500;, score=0.902 total time=   9.1s\n",
      "[CV 4/5; 4/9] START max_depth=25, n_estimators=500..............................\n",
      "[CV 4/5; 4/9] END max_depth=25, n_estimators=500;, score=0.901 total time=   9.2s\n",
      "[CV 5/5; 4/9] START max_depth=25, n_estimators=500..............................\n",
      "[CV 5/5; 4/9] END max_depth=25, n_estimators=500;, score=0.902 total time=   9.7s\n",
      "[CV 1/5; 5/9] START max_depth=25, n_estimators=1000.............................\n",
      "[CV 1/5; 5/9] END max_depth=25, n_estimators=1000;, score=0.901 total time=  18.8s\n",
      "[CV 2/5; 5/9] START max_depth=25, n_estimators=1000.............................\n",
      "[CV 2/5; 5/9] END max_depth=25, n_estimators=1000;, score=0.902 total time=  18.5s\n",
      "[CV 3/5; 5/9] START max_depth=25, n_estimators=1000.............................\n",
      "[CV 3/5; 5/9] END max_depth=25, n_estimators=1000;, score=0.902 total time=  17.9s\n",
      "[CV 4/5; 5/9] START max_depth=25, n_estimators=1000.............................\n",
      "[CV 4/5; 5/9] END max_depth=25, n_estimators=1000;, score=0.901 total time=  17.7s\n",
      "[CV 5/5; 5/9] START max_depth=25, n_estimators=1000.............................\n",
      "[CV 5/5; 5/9] END max_depth=25, n_estimators=1000;, score=0.901 total time=  17.4s\n",
      "[CV 1/5; 6/9] START max_depth=25, n_estimators=1500.............................\n",
      "[CV 1/5; 6/9] END max_depth=25, n_estimators=1500;, score=0.901 total time=  27.0s\n",
      "[CV 2/5; 6/9] START max_depth=25, n_estimators=1500.............................\n",
      "[CV 2/5; 6/9] END max_depth=25, n_estimators=1500;, score=0.902 total time=  27.3s\n",
      "[CV 3/5; 6/9] START max_depth=25, n_estimators=1500.............................\n",
      "[CV 3/5; 6/9] END max_depth=25, n_estimators=1500;, score=0.902 total time=  28.4s\n",
      "[CV 4/5; 6/9] START max_depth=25, n_estimators=1500.............................\n",
      "[CV 4/5; 6/9] END max_depth=25, n_estimators=1500;, score=0.901 total time=  28.4s\n",
      "[CV 5/5; 6/9] START max_depth=25, n_estimators=1500.............................\n",
      "[CV 5/5; 6/9] END max_depth=25, n_estimators=1500;, score=0.901 total time=  28.4s\n",
      "[CV 1/5; 7/9] START max_depth=50, n_estimators=500..............................\n",
      "[CV 1/5; 7/9] END max_depth=50, n_estimators=500;, score=0.902 total time=  17.0s\n",
      "[CV 2/5; 7/9] START max_depth=50, n_estimators=500..............................\n",
      "[CV 2/5; 7/9] END max_depth=50, n_estimators=500;, score=0.902 total time=  17.2s\n",
      "[CV 3/5; 7/9] START max_depth=50, n_estimators=500..............................\n",
      "[CV 3/5; 7/9] END max_depth=50, n_estimators=500;, score=0.904 total time=  16.6s\n",
      "[CV 4/5; 7/9] START max_depth=50, n_estimators=500..............................\n",
      "[CV 4/5; 7/9] END max_depth=50, n_estimators=500;, score=0.902 total time=  16.7s\n",
      "[CV 5/5; 7/9] START max_depth=50, n_estimators=500..............................\n",
      "[CV 5/5; 7/9] END max_depth=50, n_estimators=500;, score=0.903 total time=  18.0s\n",
      "[CV 1/5; 8/9] START max_depth=50, n_estimators=1000.............................\n",
      "[CV 1/5; 8/9] END max_depth=50, n_estimators=1000;, score=0.902 total time=  35.6s\n",
      "[CV 2/5; 8/9] START max_depth=50, n_estimators=1000.............................\n",
      "[CV 2/5; 8/9] END max_depth=50, n_estimators=1000;, score=0.902 total time=  32.4s\n",
      "[CV 3/5; 8/9] START max_depth=50, n_estimators=1000.............................\n",
      "[CV 3/5; 8/9] END max_depth=50, n_estimators=1000;, score=0.904 total time=  34.3s\n",
      "[CV 4/5; 8/9] START max_depth=50, n_estimators=1000.............................\n",
      "[CV 4/5; 8/9] END max_depth=50, n_estimators=1000;, score=0.901 total time=  31.1s\n",
      "[CV 5/5; 8/9] START max_depth=50, n_estimators=1000.............................\n",
      "[CV 5/5; 8/9] END max_depth=50, n_estimators=1000;, score=0.903 total time=  32.7s\n",
      "[CV 1/5; 9/9] START max_depth=50, n_estimators=1500.............................\n",
      "[CV 1/5; 9/9] END max_depth=50, n_estimators=1500;, score=0.902 total time=  47.6s\n",
      "[CV 2/5; 9/9] START max_depth=50, n_estimators=1500.............................\n",
      "[CV 2/5; 9/9] END max_depth=50, n_estimators=1500;, score=0.901 total time=  46.0s\n",
      "[CV 3/5; 9/9] START max_depth=50, n_estimators=1500.............................\n",
      "[CV 3/5; 9/9] END max_depth=50, n_estimators=1500;, score=0.904 total time=  46.0s\n",
      "[CV 4/5; 9/9] START max_depth=50, n_estimators=1500.............................\n",
      "[CV 4/5; 9/9] END max_depth=50, n_estimators=1500;, score=0.900 total time=  55.7s\n",
      "[CV 5/5; 9/9] START max_depth=50, n_estimators=1500.............................\n",
      "[CV 5/5; 9/9] END max_depth=50, n_estimators=1500;, score=0.903 total time= 1.0min\n",
      "CPU times: total: 15min 10s\n",
      "Wall time: 15min 27s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [10, 25, 50],\n",
       "                         &#x27;n_estimators&#x27;: [500, 1000, 1500]},\n",
       "             scoring=&#x27;f1&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [10, 25, 50],\n",
       "                         &#x27;n_estimators&#x27;: [500, 1000, 1500]},\n",
       "             scoring=&#x27;f1&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'max_depth': [10, 25, 50],\n",
       "                         'n_estimators': [500, 1000, 1500]},\n",
       "             scoring='f1', verbose=10)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "params = {\n",
    "    'n_estimators': [500, 1000, 1500],\n",
    "    'max_depth': [10,25,50]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(model, params, scoring='f1', verbose=10)\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 50, 'n_estimators': 500}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "clf = RandomForestClassifier(n_estimators = 500, max_depth = 50, random_state=42)\n",
    "\n",
    "# –æ–±—É—á–∞–µ–º –µ–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "clf = clf.fit(train_X, train_y)\n",
    "\n",
    "# –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "pred = clf.predict(test_X)\n",
    "pred_proba = clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8281481481481482\n",
      "F1:  0.5063051702395965\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(test_y, pred))\n",
    "print('F1: ', f1_score(test_y, pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.06      0.11       243\n",
      "           1       0.83      1.00      0.90      1107\n",
      "\n",
      "    accuracy                           0.83      1350\n",
      "   macro avg       0.83      0.53      0.51      1350\n",
      "weighted avg       0.83      0.83      0.76      1350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7806662428764206"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_y, pred_proba[:,1], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGDB (C—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã–π –±—É—Å—Ç–∏–Ω–≥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = LGBMClassifier(random_state=42)\n",
    "params = {\n",
    "    'num_leaves': [5, 15, 31], # default=31\n",
    "    'max_depth': [-1, 3, 7], # default=-1\n",
    "    'learning_rate': [0.5, 0.1, 0.01], # default=0.1\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(model, params, scoring='f1', verbose=10)\n",
    "#clf.fit(train_X, le.transform(train_y))\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 7, 'num_leaves': 31}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving time after GridSearch\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "clf = LGBMClassifier(**{'learning_rate': 0.1, 'max_depth': 7, 'num_leaves': 31}, random_state=42)\n",
    "clf.fit(train_X, train_y);\n",
    "\n",
    "# –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "pred = clf.predict(test_X)\n",
    "pred_proba = clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8251851851851851\n",
      "F1:  0.4943146105936804\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(test_y, pred))\n",
    "print('F1: ', f1_score(test_y, pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.05      0.09       243\n",
      "           1       0.83      1.00      0.90      1107\n",
      "\n",
      "    accuracy                           0.83      1350\n",
      "   macro avg       0.78      0.52      0.49      1350\n",
      "weighted avg       0.81      0.83      0.76      1350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7786588153947382"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(le.transform(test_y), pred_proba[:,1], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText emb + LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fasttext\n",
    "#!pip install fasttext-0.9.2-cp311-cp311-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package fasttext:\n",
      "\n",
      "NAME\n",
      "    fasttext\n",
      "\n",
      "DESCRIPTION\n",
      "    # Copyright (c) 2017-present, Facebook, Inc.\n",
      "    # All rights reserved.\n",
      "    #\n",
      "    # This source code is licensed under the MIT license found in the\n",
      "    # LICENSE file in the root directory of this source tree.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    FastText\n",
      "    tests (package)\n",
      "    util (package)\n",
      "\n",
      "DATA\n",
      "    BOW = '<'\n",
      "    EOS = '</s>'\n",
      "    EOW = '>'\n",
      "\n",
      "FILE\n",
      "    d:\\python\\anaconda3\\lib\\site-packages\\fasttext\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä–∞—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å —É–º–µ–Ω—å—à–µ–Ω–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é (–¥–æ 100) –æ—Ç facebook\n",
    "model_path = hf_hub_download(repo_id=\"kernela/fasttext-ru-vectors-dim-100\", filename=\"ru-vectors-dim-100.bin\")\n",
    "model_fasttext = fasttext.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_fasttext.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(word1, word2):\n",
    "    return np.dot(model_fasttext[word1], model_fasttext[word2]) / (np.linalg.norm(model_fasttext[word1]) * np.linalg.norm(model_fasttext[word2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8241205\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity(\"–º—É–∂—á–∏–Ω–∞\", \"–º–∞–ª—å—á–∏–∫\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_normal</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–ø–µ—Ä–µ—Å—Ç–∞—Ç—å –≤–æ–ª–Ω–æ–≤–∞—Ç—å—Å—è –º–æ—á—å –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Å...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–¥–≤–æ–µ –ø–∞—Å—Å–∞–∂–∏—Ä –∫–æ—Å–º–∏—á–µ—Å–∫–∏–π –∫–æ—Ä–∞–±–ª—å –ø—Ä–æ—Å—ã–ø–∞—Ç—å—Å—è ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–¥–∞–≤–Ω–æ –≤–∏–¥–µ—Ç—å —Ç–∞–∫–æ–π –±—Ä–µ–¥–æ–≤—ã–π —Ñ–∏–ª—å–º –ø–∞—Å—Å–∞–∂–∏—Ä –æ—Ç–∑...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>—á–µ–ª–æ–≤–µ–∫ –Ω—É–∂–Ω—ã–π —á–µ–ª–æ–≤–µ–∫ –æ—á–µ–Ω—å —Ö–æ—Ç–µ—Ç—å—Å—è –æ—á–µ–Ω—å –ø—Ä...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–Ω–µ–ø–ª–æ—Ö–æ–π –≤–∞—Ä–∏–∞—Ü–∏—è —Ç–µ–º–∞ –∫–æ—Å–º–æ—Å –æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–æ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6742</th>\n",
       "      <td>—Ñ–∏–ª—å–º –∫–æ—Ç–æ—Ä—ã–π —Å—Ç–æ–∏—Ç—å –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6743</th>\n",
       "      <td>–∑–∞–≤–æ—Ä–∞–∂–∏–≤–∞—Ç—å breathtaking</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6744</th>\n",
       "      <td>–º–∞–ª–µ—Ñ–∏—Å–µ–Ω—Ç —Å–∏–∫–≤–µ–ª —É–¥–∞—Ç—å—Å—è –º–æ–π –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ –ø—Ä–æ—Å...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6745</th>\n",
       "      <td>–≤–∞—É</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6746</th>\n",
       "      <td>–∫—Ä–∞—Å–∏–≤—ã–π —Å–∫–∞–∑–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–π —Å—é–∂–µ—Ç –ø–æ–Ω–∏–º–∞—Ç—å –ø...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6747 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_normal  y\n",
       "0     –ø–µ—Ä–µ—Å—Ç–∞—Ç—å –≤–æ–ª–Ω–æ–≤–∞—Ç—å—Å—è –º–æ—á—å –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Å...  1\n",
       "1     –¥–≤–æ–µ –ø–∞—Å—Å–∞–∂–∏—Ä –∫–æ—Å–º–∏—á–µ—Å–∫–∏–π –∫–æ—Ä–∞–±–ª—å –ø—Ä–æ—Å—ã–ø–∞—Ç—å—Å—è ...  1\n",
       "2     –¥–∞–≤–Ω–æ –≤–∏–¥–µ—Ç—å —Ç–∞–∫–æ–π –±—Ä–µ–¥–æ–≤—ã–π —Ñ–∏–ª—å–º –ø–∞—Å—Å–∞–∂–∏—Ä –æ—Ç–∑...  0\n",
       "3     —á–µ–ª–æ–≤–µ–∫ –Ω—É–∂–Ω—ã–π —á–µ–ª–æ–≤–µ–∫ –æ—á–µ–Ω—å —Ö–æ—Ç–µ—Ç—å—Å—è –æ—á–µ–Ω—å –ø—Ä...  1\n",
       "4             –Ω–µ–ø–ª–æ—Ö–æ–π –≤–∞—Ä–∏–∞—Ü–∏—è —Ç–µ–º–∞ –∫–æ—Å–º–æ—Å –æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–æ  1\n",
       "...                                                 ... ..\n",
       "6742                    —Ñ–∏–ª—å–º –∫–æ—Ç–æ—Ä—ã–π —Å—Ç–æ–∏—Ç—å –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å  1\n",
       "6743                          –∑–∞–≤–æ—Ä–∞–∂–∏–≤–∞—Ç—å breathtaking  1\n",
       "6744  –º–∞–ª–µ—Ñ–∏—Å–µ–Ω—Ç —Å–∏–∫–≤–µ–ª —É–¥–∞—Ç—å—Å—è –º–æ–π –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ –ø—Ä–æ—Å...  1\n",
       "6745                                                –≤–∞—É  1\n",
       "6746  –∫—Ä–∞—Å–∏–≤—ã–π —Å–∫–∞–∑–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–π —Å—é–∂–µ—Ç –ø–æ–Ω–∏–º–∞—Ç—å –ø...  1\n",
       "\n",
       "[6747 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([texts_normal, y]).transpose()\n",
    "df.columns=['text_normal', 'y']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ —Å –Ω–æ–º—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤\n",
    "pd.to_pickle(df, \"data_norm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15268481989f4ac2b204d4420b54c076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "embeddings = df['text_normal'].progress_apply(model_fasttext.get_sentence_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(np.array(embeddings.tolist()), y, test_size=0.20, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = LGBMClassifier(random_state=42)\n",
    "params = {\n",
    "    'num_leaves': [5, 15, 31], # default=31\n",
    "    'max_depth': [-1, 3, 7], # default=-1\n",
    "    'learning_rate': [0.5, 0.1, 0.01], # default=0.1\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(model, params, scoring='f1', verbose=10)\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'num_leaves': 5}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4428, number of negative: 969\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25498\n",
      "[LightGBM] [Info] Number of data points in the train set: 5397, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.820456 -> initscore=1.519439\n",
      "[LightGBM] [Info] Start training from score 1.519439\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = LGBMClassifier(**{'learning_rate': 0.1, 'max_depth': 3, 'num_leaves': 5}, random_state=42)\n",
    "clf.fit(train_X, train_y);\n",
    "\n",
    "# –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "pred = clf.predict(test_X)\n",
    "pred_proba = clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8296296296296296\n",
      "F1:  0.5557304335384176\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(test_y, pred))\n",
    "print('F1: ', f1_score(test_y, pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8005100352786793"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_y, pred_proba[:,1], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText emb + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_y, test_y = train_test_split(texts_normal, y, test_size=0.20, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(min_df=2, ngram_range=(1, 2),\n",
       "                vocabulary=[&#x27;,&#x27;, &#x27;.&#x27;, &#x27;–∏&#x27;, &#x27;–≤&#x27;, &#x27;&lt;/s&gt;&#x27;, &#x27;:&#x27;, &#x27;)&#x27;, &#x27;(&#x27;, &#x27;–Ω–∞&#x27;,\n",
       "                            &#x27;&quot;&#x27;, &#x27;—Å&#x27;, &#x27;–Ω–µ&#x27;, &#x27;¬ª&#x27;, &#x27;–¥–ª—è&#x27;, &#x27;-&#x27;, &#x27;¬´&#x27;, &#x27;/&#x27;, &#x27;–ø–æ&#x27;,\n",
       "                            &#x27;‚Äî&#x27;, &#x27;—á—Ç–æ&#x27;, &#x27;–í&#x27;, &#x27;!&#x27;, &#x27;–∏–∑&#x27;, &#x27;–æ—Ç&#x27;, &#x27;–∫&#x27;, &#x27;–∫–∞–∫&#x27;, &#x27;?&#x27;,\n",
       "                            &#x27;–∞&#x27;, &#x27;‚Äì&#x27;, &#x27;–∑–∞&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(min_df=2, ngram_range=(1, 2),\n",
       "                vocabulary=[&#x27;,&#x27;, &#x27;.&#x27;, &#x27;–∏&#x27;, &#x27;–≤&#x27;, &#x27;&lt;/s&gt;&#x27;, &#x27;:&#x27;, &#x27;)&#x27;, &#x27;(&#x27;, &#x27;–Ω–∞&#x27;,\n",
       "                            &#x27;&quot;&#x27;, &#x27;—Å&#x27;, &#x27;–Ω–µ&#x27;, &#x27;¬ª&#x27;, &#x27;–¥–ª—è&#x27;, &#x27;-&#x27;, &#x27;¬´&#x27;, &#x27;/&#x27;, &#x27;–ø–æ&#x27;,\n",
       "                            &#x27;‚Äî&#x27;, &#x27;—á—Ç–æ&#x27;, &#x27;–í&#x27;, &#x27;!&#x27;, &#x27;–∏–∑&#x27;, &#x27;–æ—Ç&#x27;, &#x27;–∫&#x27;, &#x27;–∫–∞–∫&#x27;, &#x27;?&#x27;,\n",
       "                            &#x27;–∞&#x27;, &#x27;‚Äì&#x27;, &#x27;–∑–∞&#x27;, ...])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(min_df=2, ngram_range=(1, 2),\n",
       "                vocabulary=[',', '.', '–∏', '–≤', '</s>', ':', ')', '(', '–Ω–∞',\n",
       "                            '\"', '—Å', '–Ω–µ', '¬ª', '–¥–ª—è', '-', '¬´', '/', '–ø–æ',\n",
       "                            '‚Äî', '—á—Ç–æ', '–í', '!', '–∏–∑', '–æ—Ç', '–∫', '–∫–∞–∫', '?',\n",
       "                            '–∞', '‚Äì', '–∑–∞', ...])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=model_fasttext.get_words(), ngram_range=(1,2), min_df=2)\n",
    "vectorizer.fit(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–±—É—á–∞–µ–º TF-IDF –Ω–∞ train, –∞ –∑–∞—Ç–µ–º –ø—Ä–∏–º–µ–Ω—è–µ–º –∫ train –∏ test\n",
    "train_X_tfidf = vectorizer.fit_transform(train_texts)\n",
    "test_X_tfidf  = vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "—Ñ–∏–ª—å–º                                              Score: 383.1926263860503\n",
      "—Ö–æ—Ä–æ—à–∏–π                                            Score: 178.44584044817157\n",
      "—Å–º–æ—Ç—Ä–µ—Ç—å                                           Score: 115.66711741641754\n",
      "–æ—á–µ–Ω—å                                              Score: 111.56906994847239\n",
      "—ç—Ç–æ                                                Score: 92.38582773668638\n",
      "–∫–æ—Ç–æ—Ä—ã–π                                            Score: 78.88806054745073\n",
      "–ø—Ä–æ—Å–º–æ—Ç—Ä                                           Score: 75.12107809807551\n",
      "—à–µ–¥–µ–≤—Ä                                             Score: 74.6171813299039\n",
      "—Å–ª–µ–∑–∞                                              Score: 64.37976826727315\n",
      "–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å                                         Score: 63.047771785893744\n",
      "–∂–∏–∑–Ω—å                                              Score: 61.830475832528485\n",
      "–ø–æ–Ω—Ä–∞–≤–∏—Ç—å—Å—è                                        Score: 59.86405620918947\n",
      "–≤—Ä–µ–º—è                                              Score: 59.43778057654602\n",
      "–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π                                      Score: 58.65035902089993\n",
      "–æ—Ç–ª–∏—á–Ω—ã–π                                           Score: 57.72096244058349\n",
      "–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ                                        Score: 51.99720997318098\n",
      "—Å—Ç–æ–∏—Ç—å                                             Score: 51.3640133332866\n",
      "—Å–∞–º—ã–π                                              Score: 49.2689322416685\n",
      "–∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π                                         Score: 48.825171596171074\n",
      "—à–∏–∫–∞—Ä–Ω—ã–π                                           Score: 48.79097338144125\n"
     ]
    }
   ],
   "source": [
    "display_scores(vectorizer, train_X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names_out()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–¥—Å—á–µ—Ç —ç–º–±–µ–¥–∏–Ω–≥–∞ fasttext c –≤–µ—Å–∞–º–∏ tf-idf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_emb_with_tfidf(sents, vectorized):\n",
    "    embeddings = []\n",
    "    with tqdm(total=vectorized.shape[0]) as pbar:\n",
    "        for n, row in enumerate(vectorized):\n",
    "            _, idx = row.nonzero()\n",
    "            tfidf_weights = row[0, idx].toarray()[0]\n",
    "            emb = np.zeros(model_fasttext.get_dimension())  \n",
    "            for weight, i in zip(tfidf_weights, idx):\n",
    "                emb_fasttext = model_fasttext.get_word_vector(vocab[i])\n",
    "                emb += weight * emb_fasttext\n",
    "            embeddings.append(emb/len(idx))  # —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "            pbar.update()\n",
    "        return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5397/5397 [00:48<00:00, 111.91it/s]\n"
     ]
    }
   ],
   "source": [
    "train_X = get_emb_with_tfidf(train_texts, train_X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1350/1350 [00:11<00:00, 112.74it/s]\n"
     ]
    }
   ],
   "source": [
    "test_X = get_emb_with_tfidf(test_texts, test_X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(random_state=42)\n",
    "params = {\n",
    "    'num_leaves': [5, 15, 31], # default=31\n",
    "    'max_depth': [-1, 3, 7], # default=-1\n",
    "    'learning_rate': [0.5, 0.1, 0.01], # default=0.1\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(model, params, scoring='f1', verbose=10)\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': -1, 'num_leaves': 31}"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "pred = clf.predict(test_X)\n",
    "pred_proba = clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8333333333333334\n",
      "F1:  0.6022439334834002\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(test_y, pred))\n",
    "print('F1: ', f1_score(test_y, pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.20      0.30       243\n",
      "           1       0.85      0.97      0.91      1107\n",
      "\n",
      "    accuracy                           0.83      1350\n",
      "   macro avg       0.73      0.59      0.60      1350\n",
      "weighted avg       0.81      0.83      0.80      1350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7919951970438771"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_y, pred_proba[:,1], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –í—ã–≤–æ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë—ã–ª–∏ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã\n",
    "\n",
    "–¢–æ—á–Ω–æ—Å—Ç—å:\n",
    "\n",
    "    TF_IDF + RandomForest:         Accuracy:  0.828 F1:  0.506\n",
    "    TF_IDF + LGDB:                 Accuracy:  0.825 F1:  0.49\n",
    "    FastText emb + LGBM:           Accuracy:  0.830 F1:  0.556\n",
    "    FastText emb + TF-IDF + LGBM:  Accuracy:  0.833 F1:  0.602\n",
    "\n",
    "–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–±–∏—Ä–∞–ª–∏—Å—å —Å –ø–æ–º–æ—â—å—é GridSearch  \n",
    "TF-IDF —Ö–æ—Ä–æ—à–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏  \n",
    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω–æ FastText —ç–º–±–µ–¥–¥–∏–Ω–≥ –Ω–µ —Å–∏–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é c TF-IDF  \n",
    "–ö–æ–º–±–∏–Ω–∞—Ü–∏—è FastText —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —Å –≤–µ—Å–∞–º–∏ TF-IDF –∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–º –±—É—Å—Ç–∏–Ω–≥–æ–º –¥–∞–ª–∏ –ª—É—á—à—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ F1 –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤. \n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
