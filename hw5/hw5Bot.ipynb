{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5. Пусть бот заговорит. Задание DaNetQA из Russian SuperGLUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть с телеграмм-ботом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с моделью DaNETQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылка на файнтьюнинг моделей: https://github.com/korolevt/otus_NLP_2023/tree/main/hw5/hw5_DaNetQA.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для загрузки модели\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ruBert-DaNetQA\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ruBert-DaNetQA\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply(text1, text2):\n",
    "  with torch.no_grad():\n",
    "    input_msg = tokenizer(text1, text2, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "    input_msg = input_msg.to(device)\n",
    "    outputs = model(**input_msg)[0]\n",
    "    output = outputs.argmax(axis=1).detach().cpu().numpy()\n",
    "    probabilities = torch.softmax(outputs, dim=-1).detach().cpu().numpy()\n",
    "    print(text1, output, probabilities.max())\n",
    "    return 'Да' if output.item() > 0.5 else 'Нет'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Осталась ли библия неизменной с момента создания? [0] 0.8368864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Нет'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply(\"Осталась ли библия неизменной с момента создания?\", \n",
    "'''10 сентября 1750 года Синод доложил императрице, что перевод готов для печати. \n",
    "18 декабря 1751 года Елизаветинская Библия вышла из печати. Все изменения, внесённые при исправлении перевода, \n",
    "были оговорены, примечания к тексту составили отдельный том, практически равный по объёму тексту самой Библии. \n",
    "Первый тираж быстро разошёлся, и в 1756 году вышло его второе издание с дополнительными примечаниями на полях и гравюрами, \n",
    "в котором иеромонах Гедеон  исправил ошибки и опечатки первого издания. В дальнейшем Русская церковь продолжила использовать \n",
    "в богослужебной практике Елизаветинскую Библию, внеся в неё лишь некоторые несущественные изменения.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Телеграм-бот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://t.me/OtusHW5QABot - ссылка на бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install telebot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot\n",
    "from telebot import types\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pyTelegramBotAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./config.json', 'r') as f:\n",
    "    json_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = json_config['tg_bot_token']\n",
    "\n",
    "bot = telebot.TeleBot(TOKEN, num_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=['start'])\n",
    "def start_message(message):\n",
    "    bot.send_message(message.chat.id,\"Проверка DaNetQA из Russian SuperGLUE!\")\n",
    "    msg = bot.send_message(message.chat.id,\"Введите текст:\")\n",
    "    bot.register_next_step_handler(msg, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question(message):\n",
    "    QA['text'] = message.text\n",
    "    print('text',QA['text'])\n",
    "    msg = bot.send_message(message.chat.id, \"Введите вопрос:\")\n",
    "    bot.register_next_step_handler(msg, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(message):\n",
    "    QA['question'] = message.text\n",
    "    print('text',QA['text'])\n",
    "    print('question',QA['question'])\n",
    "    \n",
    "    msg = bot.send_message(message.chat.id, \"Ответ:\") \n",
    "    reply = get_reply(QA['question'],QA['text'])\n",
    "    msg = bot.send_message(message.chat.id, reply) \n",
    "    msg = bot.send_message(message.chat.id, \"Для повтора нажмите /start\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.infinity_polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Была взяты данные для задачи DANetQA с бенчмарка Russian SuperGLUE (https://russiansuperglue.com/tasks/)\n",
    "\n",
    "Была зафайнтьюнета модель ruBERT-base (7 эпох)\n",
    "    \n",
    "Результаты оценки модели ruBERT (0.681 - для задачи DANetQA)::  \n",
    "![Результаты оценки модели ruBERT](ruBert-SuperGlue.jpg)    \n",
    "\n",
    "Также была проведена проверка небольшой модели cointegrated/rubert-tiny2 (2-я версия)  \n",
    "\n",
    "В модели увеличена максимальная входная длина до 2048 токенов, поэтому текст в модель поместился целеком (без обрезания)\n",
    "Для 10 эпох, результаты оказались близки к модели ruBert-base.\n",
    "\n",
    "Результаты оценки модели ruBERT-tiny2 (0.66 - для задачи DANetQA):\n",
    "![Результаты оценки модели ruBERT-tiny2](ruBert-tiny2-SuperGlue.jpg)    \n",
    "\n",
    "Для бота была взята модель ruBert-base и использовалась библиотека telebot для написания телеграмм-бота.\n",
    "\n",
    "Результаты работы бота (на тестовых данных):\n",
    "![Результаты работы бота](bot.jpg) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
